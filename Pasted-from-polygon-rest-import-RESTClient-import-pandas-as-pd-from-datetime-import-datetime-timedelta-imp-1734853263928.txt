from polygon.rest import RESTClient
import pandas as pd
from datetime import datetime, timedelta
import os
import time
from typing import Dict, Tuple, Optional
import threading
from queue import Queue
import logging

class DataHandler:
    def __init__(self):
        self.client = RESTClient(api_key=os.environ.get("b439f001-67ec-45f0-a9e0-14d641b288ac"))
        self.timeframes = {
            'daily': '1d',
            'weekly': '1wk',
            'monthly': '1mo'
        }
        self.multiplier_map = {
            '1d': (1, 'day'),
            '1wk': (1, 'week'),
            '1mo': (1, 'month')
        }
        # Enhanced caching system
        self._cache: Dict[Tuple[str, str, str], Tuple[pd.DataFrame, float]] = {}
        self._cache_lock = threading.Lock()
        self._request_queue = Queue()
        self._cache_expiry = 300  # Cache expires after 5 minutes
        
        # Rate limiting parameters
        self.calls_per_minute = 5  # Free tier limit
        self.call_timestamps = []
        self.api_lock = threading.Lock()
        
        # Setup logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

    def _check_rate_limit(self) -> float:
        """Check rate limit and return wait time if needed"""
        current_time = time.time()
        minute_ago = current_time - 60
        
        with self.api_lock:
            # Remove timestamps older than 1 minute
            self.call_timestamps = [ts for ts in self.call_timestamps if ts > minute_ago]
            
            if len(self.call_timestamps) >= self.calls_per_minute:
                # Calculate wait time until oldest call expires
                wait_time = self.call_timestamps[0] - minute_ago
                return max(0, wait_time)
            
            self.call_timestamps.append(current_time)
            return 0

    def _get_cached_data(self, cache_key: Tuple[str, str, str]) -> Optional[pd.DataFrame]:
        """Get data from cache if valid"""
        with self._cache_lock:
            if cache_key in self._cache:
                df, timestamp = self._cache[cache_key]
                if time.time() - timestamp < self._cache_expiry:
                    self.logger.info(f"Cache hit for {cache_key}")
                    return df.copy()
                else:
                    del self._cache[cache_key]
        return None

    def fetch_data(self, symbol: str, timeframe: str, period: str = '2y') -> pd.DataFrame:
        """Fetch historical data with improved error handling and caching"""
        cache_key = (symbol, timeframe, period)
        
        # Check cache first
        cached_data = self._get_cached_data(cache_key)
        if cached_data is not None:
            return cached_data

        try:
            # Calculate date range
            end_date = datetime.now()
            if period.endswith('y'):
                years = int(period[:-1])
                start_date = end_date - timedelta(days=years*365)
            elif period.endswith('m'):
                months = int(period[:-1])
                start_date = end_date - timedelta(days=months*30)
            else:
                raise ValueError("Invalid period format. Use 'Xy' for years or 'Xm' for months")

            multiplier, timespan = self.multiplier_map[self.timeframes[timeframe]]
            
            # Implement exponential backoff
            max_retries = 3
            retry_delay = 2
            
            for attempt in range(max_retries):
                try:
                    # Check and wait for rate limit
                    wait_time = self._check_rate_limit()
                    if wait_time > 0:
                        self.logger.info(f"Rate limit reached, waiting {wait_time:.2f} seconds")
                        time.sleep(wait_time)
                    
                    aggs = self.client.get_aggs(
                        symbol,
                        multiplier,
                        timespan,
                        start_date.strftime('%Y-%m-%d'),
                        end_date.strftime('%Y-%m-%d'),
                        adjusted=True
                    )
                    
                    if not aggs:
                        raise ValueError(f"No data found for {symbol}")
                    
                    # Convert to DataFrame
                    df = pd.DataFrame([{
                        'Open': agg.open,
                        'High': agg.high,
                        'Low': agg.low,
                        'Close': agg.close,
                        'Volume': agg.volume,
                        'Timestamp': agg.timestamp
                    } for agg in aggs])
                    
                    # Process DataFrame
                    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')
                    df.set_index('Timestamp', inplace=True)
                    df = df.dropna()
                    
                    # Cache the results
                    with self._cache_lock:
                        self._cache[cache_key] = (df.copy(), time.time())
                    
                    self.logger.info(f"Successfully fetched data for {symbol}")
                    return df
                    
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries - 1:
                        wait_time = retry_delay * (2 ** attempt)
                        self.logger.warning(f"Rate limit hit, waiting {wait_time} seconds before retry {attempt + 1}")
                        time.sleep(wait_time)
                        continue
                    raise
            
            raise Exception(f"Failed to fetch data after {max_retries} retries")
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg:
                self.logger.error("Rate limit exceeded")
                raise Exception("Rate limit exceeded. The application will retry automatically.")
            else:
                self.logger.error(f"Error fetching data: {error_msg}")
                raise Exception(f"Error fetching data: {error_msg}")

    def validate_data(self, df: pd.DataFrame) -> bool:
        """Validate the fetched data"""
        if df.empty:
            return False
        required_columns = {'Open', 'High', 'Low', 'Close', 'Volume'}
        return all(col in df.columns for col in required_columns)
